{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for the ML\n",
    "## Functions for setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "req = requests.get('https://www.worldometers.info/coronavirus/')\n",
    "soup = BeautifulSoup(req.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict Replace\n",
    "ecology_dict = {\n",
    "    \"poor\":1,\n",
    "    \"no data\":0,\n",
    "    \"good\":2,\n",
    "    \"excellent\":4,\n",
    "    \"satisfactory\":3\n",
    "}\n",
    "#data.ecology = data.ecology.replace(to_replace=ecology_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding OBJ columns\n",
    "\n",
    "# obj = meth.loc[:,meth.dtypes == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_user(user):\n",
    "    if user == '#error':\n",
    "        return \"\"\n",
    "    else:\n",
    "        return user[user.find('u'):]\n",
    "#log.user_id = log.user_id.apply(fix_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gender replacement\n",
    "# meth_quant['guardian'].replace({'mother':0, 'father':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COrr Score\n",
    "\n",
    "#meth_quant.corr().score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\\nscores = {leaf_size: get_mae_randf(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\\nprint(scores)\\n\\n# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\\nbest_tree_size = min(scores, key=scores.get)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### a function for scores evaluation for get_mae function\n",
    "'''candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "scores = {leaf_size: get_mae_randf(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\n",
    "print(scores)\n",
    "\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "best_tree_size = min(scores, key=scores.get)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## column transformation\n",
    "def dollar_to_number(x):\n",
    "    if x == '$':\n",
    "        return 1\n",
    "    if x == '$$-$$$':\n",
    "        return 2\n",
    "    if x == '$$$$':\n",
    "        return 3\n",
    "    else:\n",
    "        return 1\n",
    "# data4['Price Range'] = data['Price Range'].apply(dollar_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "############unification of samples\n",
    "#df_train['sample'] = 1 #train\n",
    "#df_test['sample'] = 0 #test\n",
    "#df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "#data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
    "\n",
    "############separation afterwards\n",
    "\n",
    "#train_data = data.query('sample == 1').drop(['sample'], axis=1)\n",
    "#test_data = data.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "#y = train_data.Rating.values            # наш таргет\n",
    "#X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполним очистку от лишних символов\n",
    "#data['Cuisine Style'] = data['Cuisine Style'].apply(lambda x: x.replace('[', ''))\n",
    "#data['Cuisine Style'] = data['Cuisine Style'].apply(lambda x: x.replace(']', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RE SEARCH\n",
    "import re\n",
    "\n",
    "def sep_date(date):\n",
    "    result = re.search(r'\\ ', date)\n",
    "    if result:\n",
    "        return result.group(0)\n",
    "    else:\n",
    "        return ''\n",
    "#log['date'] = log.time.apply(sep_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### РАзберемся со временем\n",
    "# data['empty_Reviews'] = (data['Reviews']=='[[], []]').astype('float64')\n",
    "\n",
    "# анализ тестовой базы выявил два пропуска, несмотря на то, что pandas.profiling на тренировочной базе пропусков не выявил, заполним их '[[], []]' и закинем в empty_Reviews\n",
    "# data['Reviews'] = data['Reviews'].fillna('[[], []]')\n",
    "# data['empty_Reviews'] = (data['Reviews']=='[[], []]').astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['date_of_Review'] = data['Reviews'].str.findall('\\d+/\\d+/\\d+')\n",
    "## finding review dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['len_date'] = data['date_of_Review'].apply(lambda x: len(x)) ## length from date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['len_date'].date_of_Review = data[data['len_date']==3].date_of_Review.apply(lambda x: x.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['one_Review'] = (data['len_date']==1).astype('float64') ## restaurants with only one review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_now(row):\n",
    "    if row['date_of_Review'] == []:\n",
    "        return None\n",
    "    return datetime.datetime.now() - pd.to_datetime(row['date_of_Review']).max()\n",
    "\n",
    "def time_between_Reviews(row):\n",
    "    if row['date_of_Review'] == []:\n",
    "        return None\n",
    "    return pd.to_datetime(row['date_of_Review']).max() - pd.to_datetime(row['date_of_Review']).min()\n",
    "\n",
    "#data['day_to_now'] = data.apply(time_to_now, axis = 1).dt.days\n",
    "#data['day_between_Reviews'] = data[data['len_date']==2].apply(time_between_Reviews, axis = 1).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Заполняем пропуски\n",
    "#data['Number of Reviews'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for col in ['maker', 'origin', 'location', 'bean_type', 'bean_origin']:\\n    get_stat_dif(col)\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stat_dif(column):\n",
    "    cols = cacao.loc[:, column].value_counts().index[:10]\n",
    "    combinations_all = list(combinations(cols, 2))\n",
    "    for comb in combinations_all:\n",
    "        if ttest_ind(cacao.loc[cacao.loc[:, column] == comb[0], 'rating'], \n",
    "                        cacao.loc[cacao.loc[:, column] == comb[1], 'rating']).pvalue \\\n",
    "            <= 0.05/len(combinations_all): # Учли поправку Бонферони\n",
    "            print('Найдены статистически значимые различия для колонки', column)\n",
    "            break\n",
    "            \n",
    "'''for col in ['maker', 'origin', 'location', 'bean_type', 'bean_origin']:\n",
    "    get_stat_dif(col)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get MAE for N amount of leaves\n",
    "def get_mae_randf(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes, random_state=42)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"categorical_features = ['City']\\ncategorical_transformer = Pipeline(steps=[\\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "'''numeric_features = ['Ranking','Price Range','Number of Reviews']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])''' ###--- NUMERIC\n",
    "\n",
    "'''categorical_features = ['City']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])''' ###--- CATEGORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"preprocessor = ColumnTransformer(\\n    transformers=[\\n        ('num', numeric_transformer, numeric_features),\\n        ('cat', categorical_transformer, categorical_features)])\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessor\n",
    "'''preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"clf = Pipeline(steps=[('preprocessor', preprocessor),\\n                      ('classifier', LogisticRegression(solver='lbfgs'))])\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Full model (clf.fit)\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "'''clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data_temp = data.loc[data['sample'] == 1, list(feat_importances.nlargest(15).index[0:15])]\\nplt.rcParams['figure.figsize'] = (12,6)\\nax = sns.heatmap(data_temp.corr(), annot=True, fmt='.2g')\\ni, k = ax.get_ylim()\\nax.set_ylim(i+0.5, k-0.5)\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CORR\n",
    "'''data_temp = data.loc[data['sample'] == 1, list(feat_importances.nlargest(15).index[0:15])]\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "ax = sns.heatmap(data_temp.corr(), annot=True, fmt='.2g')\n",
    "i, k = ax.get_ylim()\n",
    "ax.set_ylim(i+0.5, k-0.5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor col in meth_quant.columns:\\n    get_boxplot(col)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BoxPlots\n",
    "def get_boxplot(column):\n",
    "    fig, ax = plt.subplots(figsize = (14, 4))\n",
    "    sns.boxplot(x=column, y='score', \n",
    "                data=meth_quant,\n",
    "               ax=ax)\n",
    "    plt.xticks(rotation=45)\n",
    "    ax.set_title('Boxplot for ' + column)\n",
    "    plt.show()\n",
    "'''\n",
    "for col in meth_quant.columns:\n",
    "    get_boxplot(col)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c = 0\\nfor test in test_models:\\n    plt.plot(test, label=models_list[c])\\n    c += 1\\n    \\nplt.plot(y_test.iloc[0], label = \"Real Data\")\\nplt.legend()'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot\n",
    "'''c = 0\n",
    "for test in test_models:\n",
    "    plt.plot(test, label=models_list[c])\n",
    "    c += 1\n",
    "    \n",
    "plt.plot(y_test.iloc[0], label = \"Real Data\")\n",
    "plt.legend()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metrics_list = (\"mae\", \"mse\", \"msle\")\\nc = 0\\nfor test in test_models:\\n    \\n    mae = mean_absolute_error(test, y_test.iloc[0])\\n    mse = mean_squared_error(test, y_test.iloc[0])\\n    msle = mean_squared_log_error(test, y_test.iloc[0])\\n    print(f\"{models_list[c]} errors:  MAE-{mae}, MSE-{mse}, msle-{msle}\")\\n    c += 1\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Measuring Error\n",
    "##Metrics\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "'''metrics_list = (\"mae\", \"mse\", \"msle\")\n",
    "c = 0\n",
    "for test in test_models:\n",
    "    \n",
    "    mae = mean_absolute_error(test, y_test.iloc[0])\n",
    "    mse = mean_squared_error(test, y_test.iloc[0])\n",
    "    msle = mean_squared_log_error(test, y_test.iloc[0])\n",
    "    print(f\"{models_list[c]} errors:  MAE-{mae}, MSE-{mse}, msle-{msle}\")\n",
    "    c += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncorr.style.background_gradient(cmap, axis=1)    .set_properties(**{\\'max-width\\': \\'80px\\', \\'font-size\\': \\'10pt\\'})    .set_caption(\"Hover to magify\")    .set_precision(2)    .set_table_styles(magnify())'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###corr2\n",
    "import seaborn as sns\n",
    "\n",
    "'''corr = train.drop(['violation_zip_code', 'payment_amount', \n",
    "                      'clean_up_cost', \n",
    "                      'violation_street_number'], axis=1).\\\n",
    "                dropna(axis=1).\\\n",
    "                corr()\n",
    "cmap = sns.diverging_palette(5, 250, as_cmap=True)'''\n",
    "\n",
    "def magnify():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"7pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])\n",
    "]\n",
    "'''\n",
    "corr.style.background_gradient(cmap, axis=1)\\\n",
    "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "    .set_caption(\"Hover to magify\")\\\n",
    "    .set_precision(2)\\\n",
    "    .set_table_styles(magnify())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_iqr(ys):\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return np.where((ys > upper_bound) | (ys < lower_bound))[0]\n",
    "# outliers_iqr(train.balance_due).max() - outliers_iqr(train.balance_due).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"median = cacao.cocoa_percent.median()\\nIQR = cacao.cocoa_percent.quantile(0.75) - cacao.cocoa_percent.quantile(0.25)\\nprint(median, IQR, median - 1.5*IQR, median + 1.5*IQR)\\ncacao.cocoa_percent.loc[cacao.cocoa_percent.between(median - 1.5*IQR, median + 1.5*IQR)].hist(bins = 16\\n                                                                                              , range = (40, 100), \\n                                                                                             label = 'IQR')\\ncacao.cocoa_percent.loc[cacao.cocoa_percent <= 100].hist(alpha = 0.5, bins = 16, range = (40, 100),\\n                                                        label = 'Здравый смысл')\\nplt.legend();\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IQR GRAPH\n",
    "'''median = cacao.cocoa_percent.median()\n",
    "IQR = cacao.cocoa_percent.quantile(0.75) - cacao.cocoa_percent.quantile(0.25)\n",
    "print(median, IQR, median - 1.5*IQR, median + 1.5*IQR)\n",
    "cacao.cocoa_percent.loc[cacao.cocoa_percent.between(median - 1.5*IQR, median + 1.5*IQR)].hist(bins = 16\n",
    "                                                                                              , range = (40, 100), \n",
    "                                                                                             label = 'IQR')\n",
    "cacao.cocoa_percent.loc[cacao.cocoa_percent <= 100].hist(alpha = 0.5, bins = 16, range = (40, 100),\n",
    "                                                        label = 'Здравый смысл')\n",
    "plt.legend();'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gmodel = MLPRegressor(random_state = 42)\\nparam_grid = {\\n    \"max_iter\" : [500,1000,2000],\\n    \"activation\" : [\"logistic\", \"relu\"]\\n}\\n\\nGS = GridSearchCV(Gmodel, param_grid, scoring = \"neg_mean_absolute_error\", cv=3)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##CROSS VALIDATION\n",
    "'''Gmodel = MLPRegressor(random_state = 42)\n",
    "param_grid = {\n",
    "    \"max_iter\" : [500,1000,2000],\n",
    "    \"activation\" : [\"logistic\", \"relu\"]\n",
    "}\n",
    "\n",
    "GS = GridSearchCV(Gmodel, param_grid, scoring = \"neg_mean_absolute_error\", cv=3)'''\n",
    "# best_model = GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
